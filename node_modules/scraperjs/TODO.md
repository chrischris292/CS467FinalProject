# TODO

+ ~~resolve jquery not being shipped with scraperjs~~ (done, 7.Ag.2014)
+ ~~make so that the dynamic scraper can read the page content after x time~~ (done, 7.Ag.2014)
+ ~~complete readme~~ (done, 8.Ag.2014)
+ ~~add close method to scrapers class, and invoke it at the same time the done promise is fired~~
+ ~~pass arguments to scraping functions (mainly phantom)~~ (done 10.Ag.2014)
+ ~~make a phantom page poll/factory~~ (done 12.Ag.2014)
    + zombie scraper
+ ~~tests~~ (done 12.Ag.2014)
+ ~~examples~~ (done 12.Ag.2014)
+ ~~export my dependencies~~ (abandoned)
+ ~~create IScraper, AbstractScraper and ScraperPromise should implement it.~~ (abandoned)
+ ~~remove cheerio for a lighter option~~ (abandoned)
+ ~~load balancer~~ (out of scope)
+ ~~505 balancer/repeater~~ (can be done with few lines of code)
+ ~~async router.route support (needs to instantiate a new scraper each time!)~~ (done 10.Ag.2014)
+ ~~router can skip~~ (done 10.Ag.2014)
+ ~~waterfall pass returns~~ (done, 22.Ag.2014)
+ ~~async scraper promise~~ (abandoned)
+ ~~router.route callback has boolean param to indicate if the path was found~~ (done 9.Ag.2014)
+ ~~add license~~ (done 8.Ag.2014)
+ ~~proxy requests~~ (already on request)
+ ~~concurrency managment~~ (out of scope/already implemented)
+ ~~check for robots~~ (out of scope)
+ ~~check for existing urls already scraped (http://en.wikipedia.org/wiki/Bloom_filter)~~ (out of scope)
+ ~~router.on(function(url):boolean)~~ (done 9.Ag.2014)
+ ~~add router.on().use(scraper)~~ (done 10.Ag.2014)
    + for a better performance on the router side, only one request needs to be done, and the body should be passed to the scrapers
+ ~~scrapers should throw error if no onError promise was set~~ (12.Ag.2014)
+ ~~scrapers tests should test utils functions~~ (done, 15.Ag.2014)
+ ~~router should test utils/skip~~ (done, 15.Ag.2014)
+ ~~async test in the router.route~~ (abandoned)
+ ~~add test coverage and badge~~ (done, 16.Ag.2014)
+ ~~add CI~~ (done, 15.Ag.2014)
    + more examples (include factory)
+ ~~more tests~~ (done, 15.Ag.2014)
+ ~~add ScraperPromise test, and it should test only one kind of scraper at each time. the current scrapers tests should be more restrict~~ (done, 15.Ag.2014)
+ ~~update readme~~ (done, 15.Ag.2014)
+ ~~check if the images are loaded in the DynamicScraper~~ (done, 17.Ag.2014)
+ ~~document PhantomPoll~~ (done, 18.Ag.2014)
+ ~~test ScraperError~~ (done, 18.Ag.2014)
+ ~~test Router (test * path, bad formating, onError)~~ (done, 18.Ag.2014)
+ ~~test AbstractScraper (error on get and request, get response and get body)~~ (done, 22.Ag.2014)
+ ~~add inject promise~~ (done, 21.Ag.2014)
+ ~~add information about grunt test~~ (done, 20.Ag.2014)
+ ~~add more information~~ (done, 21.Ag.2014)
+ ~~add keywords and other missing fields to package.json~~ (done, 22.Ag.2014)
+ ~~substitute assert.ok(!err) for assert.ifError()~~ (abondoned)
+ ~~100% code coverage~~ (done, 22.Ag.2014)
+ ~~update readme~~ (done, 24.Ag.2014)
+ ~~add api generator~~ (done, 24.Ag.2014)
+ ~~website~~ (done, 24.Ag.2014)

Ideas file:
http://jakeaustwick.me/python-web-scraping-resource